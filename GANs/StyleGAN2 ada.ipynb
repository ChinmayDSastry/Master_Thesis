{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone the repository to train StyleGAN2 ada\n",
    "\n",
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages required for setting up the training\n",
    "#Python 3.7 and Pytorch 1.7.1 Assuming Cuda Toolkit 11.0 https://pytorch.org/get-started/previous-versions/\n",
    "!pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#If Conda environment is present it is recommended to use\n",
    "!conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch\n",
    "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3 dominate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the dataset for training StyleGAN2 ada, For this it is recommended to already have the dataset with size 512x512. The images can vary from size 128 to 1024. Higher the resolution, higher is the training time. Assuming that inside the repository, dataset is stored under datasets directory for example sailboat folder inside datasets directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This command will convert the dataset into StyleGAN2 ada readable format\n",
    "#--dest is the destination where the data has to be stored\n",
    "!python dataset_tool.py --source=datasets/sailboat --dest=datasets/sailboat.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset has been created, the GAN is ready to be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train StyleGAN2 ada with the custom data.\n",
    "#it is recommended to perform a dry run to check if all the hyperparameters are set according to the user\n",
    "#GPU is dependent on the hardware. If only 1 is available then it should be set to 1. augmentation is adaptive discriminator augmentation ada, transfer learning with ffhq dataset for 3000 runs\n",
    "!python train.py --out_dir=training_runs --datasets/sailboat.zip --gpus=2 --mirror=1 --aug=ada --target=0.7 --gamma=10 --resume=ffhq512 --snap=50 --kimg=3000 --cfg=stylegan2 --dry-run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting the training \n",
    "!python train.py --out_dir=training_runs --datasets/sailboat.zip --gpus=2 --mirror=1 --aug=ada --target=0.7 --gamma=10 --resume=ffhq512 --snap=50 --kimg=3000 --cfg=stylegan2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to generate images from the trained model\n",
    "#--network gets an input of trained model which will be saved in the directory training_runs\n",
    "#Seeds are the vectors in the latent space and generate different images. It can be varied based on the input needed,\n",
    "#Output of the generator will be stored in directory out which is specified with --outdir\n",
    "python generate.py --outdir=out  --seeds=85,265,  --network=<SAVEDPKLFILE>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
